#+BIBLIOGRAPHY: ../bib plain


* Modeling consensus
  :PROPERTIES:
  :CUSTOM_ID: sec:consensus:consensus
  :END:

*** From specific protocol to general insight 

- So far, we have no idea how to be *both safe and live*
  - 2PC and 3PC made different tradeoffs, but neither achieved both
    goals
- Can we have both?
  - Fiddle with protocols?
  - Or think about the problem more systematically? 

*** Consensus

- What do we *really* want to achieve?
  - An agreed-upon decision, a *consensus* 

*** Intuition: Two-army problem 

- Two armies, one on the valley floor; the other distributed over the
  mountains
- Mountain army has to agree when to attack
- But can only use messengers, which are prone to be intercepted
- Note: equivalent to *terminating reliable broadcast*! 


#+CAPTION: Two-army problem
#+ATTR_LaTeX: :width 0.75\linewidth
#+NAME: fig:consensus:two_army
[[./figures/consensus.pdf]]




*** Consensus formalised 

- Set of processes, each process can propose 0 or 1 as desired result
- Once a process has *decided*, it cannot change that decision
  (decision becomes visible to outside world) 

#+BEAMER: \pause

- Requirements
  - *Agreement*: All processes decide on the same value
  - *Termination*: All  processes eventually decide
  - *Validity*
    - If all processes start with 0, both must decide for 0
    - If all processes start with 1 *and* all messages are delivered,
      then both must decide for 1
    - (Validity just rules out trivial algorithms; variations exist) 



* Feasible  cases

*** No failures at all 

- No node failures, no messages lost, all messages arrive in bounded
  time (*synchronous model*) 
- Easy! 
- E.g., every process sends its values to all other processes
- Then, deterministic decision rule 


*** Node fails, all messages arrive in bounded time 

- Validity here: If all processes start with same value, all
  *nonfailing* processes
  must decide for this one 
- Fault model: at most $f$ processes fail 
- Idea: broadcast in $f+1$ rounds; there must be one round where
  everybody gets every message 

*** FloodSet algorithm 

- Each process stores a subset W out of the valid values V 
- Initially: W is the value that the respective process proposes 
- After every round each process broadcasts W to all participants 
- All received elements are added to W
- After f +1 rounds each process decides
  - Has W only one element, this is the result
  - Otherwise a default value is chosen (e.g. the smallest possible
    value v0) – validity makes no requirements for the case when there
    is more than a single initial value! 


*** FloodSet algorithm 
 - Why $f +1$ rounds? 
   - At most $f$ nodes may fail 
   - With $f +1$ rounds, there is at least one round in which no node
     fails
   - Hence: in this round consensus is established 
   - $f +1$ rounds, $O((f +1)n^2)$ messages
 - Why not decide after two rounds? 
   - See homework assignment 
   - Hint: partial sending before failure
 - Optimizations possible (exponential information gathering
   algorithms which function also for other failure models) 


*** Nodes are traitors, all messages arrive in bounded time 

- So-called *Byzantine agreement*  \cite{Lamport:1982:BGP:357172.357176}
- Solvable provided there are at least $n = 3f+1$ node available when
  there are $f$ traitors 
- Algorithm: see below
  \slideref{sec:consensus:byzt_alg}[s:consensus:byzt_alg] 


*** Consensus with Byzantine Processes

 - Correctness conditions
   - *Agreement*: *No two nonfaulty* processes decide on different values
   - *Validity*: If *all nonfaulty processes* start with the same value, then this value is the only valid one
   - *Termination*: *All nonfaulty* processes eventually decide
 - Remarks: 
   - Restriction of the validity conditions to only nonfaulty processes because conditions for the behavior of Byzantine processes make no sense 
   - n > 3f required (triple modular redundancy not sufficient!)
   - For failing processes such a limit does not exist!
   - An algorithm for Byzantine processes does in general not solve the consensus problem for failing processes 
   - Reason: In version for failing processes all processes that decide have to agree – even processes that fail after they have decided! 	


* Impossibility


*** \ac{FLP} result 

**** Impossibility of consensus in asynchronous systems with node failure :B_theorem:
     :PROPERTIES:
     :BEAMER_env: theorem
     :END:

In an *asynchronous* system, there is *provably no deterministic* algorithm that
allows a set of processes to find consensus on even a binary
variable, if there could be even a *single* failing
process. \cite{Fischer:1985:IDC:3149.214121} 


**** Essence  

- Combination of asynchrony and failure prevents consensus
- In synchronous system, consensus is easy -- upper bound on message
  times allows to detect failing node with certainty 


*** FLP proof 

- Omitted. Too complicated. \Smiley 

- Good explanation in, e.g., \cite{Lynch:1996:DA:525656}

*** FLP interpretation 

- Deterministic algorithms cannot *guarantee* both liveness and
  safety in *asynchronous*, possibly *faulty* systems
- FLP does *not* say that a practical algorithm cannot come reasonably
  close, reasonably often
  - Theoretically: Randomized consensus, probability of missing
    consensus can be made arbitrarily small
    - I.e: $P (\text{some nodes decide 0, others 1}) < \epsilon$
    - $\epsilon$ determines round number 
  - Practical algorithm --  RAFT -- up next (we skip PAXOS) 


*** Further consequences 

- Far-reaching implication
- E.g., reliable terminating multicast is equivalent to consensus
  under wide set of assumptions 
  - Needs agreement on which messages have been received by which
    nodes
- Hence: reliable terminating multicast is impossible to achieve
  deterministically! 


*** Summary impossible cases 

#+CAPTION: A summary of possible and impossible cases for consensus (following \cite[Fig. 8.17]{Tanenbaum:2006:DSP:1202502}) 
#+ATTR_LaTeX: :width 0.9\linewidth 
#+NAME: fig:consensus:imposible_summary
[[./figures/impossible.pdf]]


* Raft

** A practical consensus protocol 

*** Practical candidates

- For realistic, yet nontrivial cases, finding good protocols is hard
  (as the problem is hard) 
  - Combining asynchrony with fault tolerance in a meaningful way 
- Two main candidates
  - PAXOS: provably correct consensus protocol 
    - E.g., used in Zookeeper, Kafka, Google's Chubby,  ...
    - Original publication considered difficult to read
      \cite{Lamport:1998:PP:279227.279229}; followup paper tried to
      simplify exposition \cite{paxos-made-simple}; tutorial
      \cite{Meling2013}
    - Notorious for being  difficult to understand and to implement
  - Raft \cite{10.5555/2643634.2643666}: Simpler structure, same guarantees


*** Raft goal: Log replication  

*Log replication* for replicated (deterministic) finite state machines 
- Suppose we have an FSM, replicated on multiple machines 
- Clients issue events (commands) to that FSM 
- Goal: Ensure that all commands appear in the same order at all
  machines
  - Commands are stored in a *command log*, hence the name 
  - Consensus on order! 
  - Recall total order multicast!!
- Formally:
  - *Safety*: Never return an incorrect result
  - *Available*: As long as any majority of servers is operational and
    can communicate, progress is made
  - *Timing-independent*: Specific, precise choice of timer values
    does not matter 

*** Challenges

  - Machines can fail and recover
  - Message lost, arbitrarily delayed
  - Membership changes (nodes added, dropped) 

We *finally* build a really fault-tolerant protocol for the general
case! 

*** Raft  sources 

- Main paper: \cite{10.5555/2643634.2643666}
- Extended version:  \cite{ongaro14:_in_searc_under_consen_algor_exten_version}
  - Strongly recommended to read it! Very accessible, clear
    presentation; good comparison to Paxos and limitations of formal proofs!
  - Section here mostly follows this paper 
- Github presence: \cite{raft20:_raft_consen_algor_github}
- Animation \cite{raft20:_secret_lives_data}


** Raft structure 

*** Components 

- Leader election
  - Already covered -- compare Section \ref{sec:raft_le}
- Log replication 
- Safety mechanisms 

*** Raft basics 

(Compare \cite[Section 5]{ongaro14:_in_searc_under_consen_algor_exten_version})  

**** Terms and leaders 

- Leaders are elected and responsible for terms of varying duration 
- Term numbers are monotonically increasing
- Term numbers are a *logical clock*
  - Whenever a term number larger than a machine's own term is seen,
    it is updated to larger number 
- Any term has *at most* one leader
  - It might have none if leader election fails 

*** Raft basics (2)


**** Clients and leaders 

- Clients issue events/actions to replicated FSM 
- Clients only talk to leaders 
  - Non-leaders redirect clients to current leader 


**** Leaders and log 

- Only leader appends to log to ensure order 
- Leader only confirms to client once it has confirmation from
  majority of servers 
- Challenge: what happens when leader election and log updates
  overlap? 


** Log replication 

*** Log replication 

The log: 

- List of commands for the FSM, held by each node 
- Index by (term, index inside term) tuple 
- Logs contain *committed* and *uncommitted* entries
  - Committed entries are a prefix (if one entry is committed, so are
    all its predecessors; identified by *commit counter* 
    - This highest index is included in all leader messages 
  - *Committed*: Safe to apply command to FSM 
  - *Uncommitted*: Still not sufficiently confirmed from other
    replicas 

*** Log example 

#+CAPTION: Example Raft log; colors and numbers show terms (Figure 6 from \cite{ongaro14:_in_searc_under_consen_algor_exten_version})
#+ATTR_LaTeX: :width 0.6\textheight
#+ATTR_LaTeX: :caption \caption{Example Raft log (Figure 6 from \cite{}) \label{fig:raft:log}}
#+NAME: fig:raft:log
[[./figures/raft_log.pdf]]

Note that not all followers are up to date with the committed index of
the current leader 

*** Basic operation for log replication 

- Client sends command to leader 
- Leader appends command to its log (as uncommitted entry)
- Sends command to all followers to replicate it
  - Waits for ACKs from majority (condition for commit)
    - Watch out for subtleties with leader changes (see below)
  - Retries indefinitely! 
- Followers only accept and ACK command if no gap in index sequence!
- With enough ACKs, leader
  - commits entry,
  - applies it to its FSM 
  - sends result of FSM action back to client 



*** Properties 

To quote \cite{ongaro14:_in_searc_under_consen_algor_exten_version}: 

If two entries in different logs have the same index and term, then
- they store the same command 
- the logs are identical in all preceding entries 



*** Committing on followers 

- Leader decides when a log entry can be committed
  - Leads to update of commit counter 
- Commit counter is distributed to followers
  - At least with heartbeats!
- Hence, followers can find out which entires are committed and should
  be applied to state machine 




** Leader crash 

*** Problem: Leader crash 

Logs of new leader in new term might be inconsistent with follower
logs; these are *uncommitted* entries  

#+CAPTION: Logs when leader changes (Figure 7 from \cite{ongaro14:_in_searc_under_consen_algor_exten_version})
#+ATTR_LaTeX: :width 0.6\textheight
#+ATTR_LaTeX: :caption \caption{Logs when leader changes (Figure 7 from \cite{ongaro14:_in_searc_under_consen_algor_exten_version}) \label{fig:raft:log_leader_change}}
#+NAME: fig:raft:log_leader_change
[[./figures/raft_log_leader_change.pdf]]

*** Possible options 


**** Cases 

- Case a, b: Unproblematic; new leader has superset
- Case c, d: Leader misses entries from previous terms
  - Could happen if those nodes where leader in previous terms, but
    did not manage to commit them 
- Case e, f: Combination 

\pause 
**** Uncommitted? 

How do we know these are uncommitted entries at other nodes? 
- Leader election needs to assure that!
- Need an additional condition there (see below!) 

*** Options 

- Send old entries from followers to new leader
  - Possible, done in some protocols, but complicated 
- Force followers to abandon their entries, follow new leader!
  - Raft approach
  - Entries in follower will be overwritten by leader log
  - Handled via consistency check: followers delete everything after
    last entry where they agree with leader
  - No specific actions needed! Normal replication will kick in after
    follower logs are shortened
\pause 
- Note: we only remove uncommitted entires
  - I.e.: not yet applied to state machine, not yet sent back to
    client
  - Client would have to resend! 


*** Consequence 


*Leader Only Appends* Property: 

- A leader only appends to its own log 
- It never deletes, inserts, reorders, ... anything in its log 


** Safety

*** Problematic case 

- Leader election so far cannot guarantee that new leader only misses
  uncommitted entries
  - As assumed above
  - If it did miss committed entries, we could not just roll back
    other logs like we did above
  - That would lead to inconsistent FSM sequences!
- Example scenario:
  - Follower A down for a term
  - Other leader B commits entires (majority of nodes is still up!)
  - A comes up, becomes leader in following term, and does lack the
    committed entries 
\pause 
- Hence: We need a restriction on leader election to avoid such cases! 

*** Restricted leader election 

- Follower votes for a candidate only if the candidate's log is *at
  least as up to date* as the follower's log 
  - Up to date: Compare (term, index) number, lexicographically
- Ensures that candidate becomes leader only if it is at least as up
  to date as a majority of all nodes
  - Hence, it cannot miss committed (!) entries 

*** Committing entries from previous terms 

- Recall: Entries from *current* term: leader can commit once ack'ed by
  majority of participants 
- But what about entries from *previous* terms that are uncommitted? 
- Possible issue:
  - Leader crashes, has uncommitted entries
  - New leader takes over in new term; it might have copy of those
    entires 
  - New leader tries to replicate them 
  - Can new leader commit once majority has acknowledged? 

*** Majority acknowledges entries from previous terms 


****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.3
      :END:

Problem: Just because an entry is stored on majority of servers is
  not sufficient to commit it 


*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.7
      :END:


#+CAPTION: Raft unable to commit across terms (Fig. 8 from \cite{ongaro14:_in_searc_under_consen_algor_exten_version})
#+ATTR_LaTeX: :width 0.6\textheight
#+ATTR_LaTeX: :caption \caption{Raft unable to commit across terms (Fig. 8 from ) \cite{ongaro14:_in_searc_under_consen_algor_exten_version}) \label{fig:raft:no_commit}}
#+NAME: fig:raft:no_commit
[[./figures/raft_no_commit.pdf]]


*** Solution: Don't count replicas for previous term's entries 

- Basic idea: hold off until committing terms from *previous* terms
  until at least one entry from *current* term is committed 
- Then, a competing candidate (with a contradicting entry on earlier
  indices)
  - cannot possibly win a later election and
  - can, hence, not push through the contradicting entry for the
    previous term 


(The full, formal safety argument is a bit more complex, but still not
too hard \cite[Section 5.4.3]{ongaro14:_in_searc_under_consen_algor_exten_version})  

** Other mechanisms 

*** Log compaction 

  - Deal with log that grows above bounds 
  - Take a snapshot (compare Section \ref{sec:snapshot}) of entire state (logs on
    all participants) to stable storage 
  - Delete logs up to that point 

***  Membership changes
  - Challenge: Updating *configuration* is non-atomic
  - Could lead to two current leaders, some from new, some from old
    configuration 
  - Approach: during transition, require majorities from *both* old
    and new configuration 

*** Raft conclusion 

- Overall, a practical, powerful, relatively simple scheme to drive
  replicated FSMs 
- *Much* simpler compared to alternative schemes like PAXOS 


*** Membership change: Problematic example 
#+CAPTION: Two leaders during configuration change (Fig. 10 from \cite{ongaro14:_in_searc_under_consen_algor_exten_version})
#+ATTR_LaTeX: :width 0.6\textheight
#+ATTR_LaTeX: :caption \caption{Two leaders during configuration change (Fig. 10 from \cite{ongaro14:_in_searc_under_consen_algor_exten_version}) }
#+NAME: fig:raft:reconfig_two_leaders
[[./figures/raft_no_commit.pdf]]





* PAXOS
  :PROPERTIES:
  :CUSTOM_ID: sec:consensus:paxos
  :END:


** Reference algorithm 

*** Example consensus protocol: Paxos 

- Paxos is perhaps the most widely used consensus protocol in
  practical use
  - E.g., used in Zookeeper, Kafka, Google's Chubby,  ...
- Sources 
  - Original publication considered difficult to read
    \cite{Lamport:1998:PP:279227.279229} 
  - Followup paper tried to simplify exposition
    \cite{paxos-made-simple}
  - Explanation here partially follows a tutorial on Paxos
    \cite{Meling2013}; probably most easy to read 

*** Paxos 

- Paxos: A *family* of consensus protocols 
- From basic to multi to fast to Byzantine to \ldots
  - With different trade-offs possible  (number, types of failures,
    latency,   \ldots ) 
  - We will only cover the basic version here 

*** Assumptions  for basic Paxos 
- Assumptions 
  - Processors: fail-stop model, arbitrary speed; may *propose* values  
  - Network: asynchronous, connected, loss/reordering/duplication
    failures (but no corruption); partitions are hence possible!   
  - $2f+1$ processors for at most $f$  simultaneous failures 


*** Basic Paxos properties 

- Safety  (make no inconsistent decisions): 
  - Only a *single* value is chosen as result 
  - Only a *proposed* value is chosen 
  - Only a chosen value is made public
- Lifeness   (make progress) :
  - FLP result still holds
  - So Paxos sacrifices liveness (blocks on decisions) if necessary 



** Strawman 

*** Some initial thoughts 

- We saw how safety and lifeness have to be balanced
  - Timeouts vs. network partition problem
- We saw how a primary/backup approach tackles some of these issues
- Let's start from that as a strawman and see what we have to change
  to come up with a working protocol \cite{Meling2013}

*** Strawman: Primary/backup 

- Strawman protocol (cp. \slideref{sec:distStor:consistency_protocols}[s:distStor:pb_blocking]) 
  - Client talks to a primary server
  - Primary distributes data to backup(s)
  - Backup(s) acknowledge to primary
  - Primary acknowledges to client 

*** Strawman: Primary/backup 


Recall figure: 

#+CAPTION: Primary with backup and blocking write operations
#+ATTR_LaTeX: :width 0.9\linewidth :options page=2
#+NAME: fig:consensus:primary_blocking_write
[[./../ch_11_distStorage/figures/updateProtocols.pdf]]

*** Strawman: Use multicast to all servers 

Slight modification: Clients multicast to all servers, spreading
information 


#+CAPTION: Primary/backup strawman with multicast
#+ATTR_LaTeX: :width 0.5\linewidth :options page=1
#+NAME: fig:consensus:pb:mutlicast
[[./figures/paxos.pdf]]




*** Server crash in strawman? 



****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


- What if the primary crashes?
- Use a leader elect protocol to a elect a new primary
- Have new primary send replies to clients 


*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


#+CAPTION: Primary/backup strawman: server crash 
#+ATTR_LaTeX: :width 0.85\linewidth :options page=2
#+NAME: fig:consensus:pb:server_crash 
[[./figures/paxos.pdf]]


*** Network partition in strawman? 

****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


- What if network partitions between the two leaders?
  - Not distinguishable from crash! 
- Leader elect protocol would elect a new leader 
- Both leaders send back replies to clients
  - Could be different replies!
  - Clients see different replies in different order \Sadey 

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


#+CAPTION: Primary/backup strawman with network partition 
#+ATTR_LaTeX: :width 0.85\linewidth :options page=3
#+NAME: fig:consensus:pb:partition
[[./figures/paxos.pdf]]

*** Strawman: Deal with  network partition 

****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

- Network partitions are unavoidable
- But replies should stay consistent
- Idea: uneven number of servers
  - Only leader in majority partition would actually answer 

****** Liveness jeopardy? 

- This jeopardises liveness if minority partition are the actual
  survivors! 

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


#+CAPTION: Server group to deal with network partition 
#+ATTR_LaTeX: :width 0.85\linewidth :options page=4
#+NAME: fig:consensus:pb:group_partition 
[[./figures/paxos.pdf]]


*** Partially healing partitions confuses 

****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

- A partially healed partition can create additional confusion
- Example: Server S1 -- deemed failed -- resends message to S3 


*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


#+CAPTION: Server group with partially healed partition 
#+ATTR_LaTeX: :width 0.85\linewidth :options page=5
#+NAME: fig:consensus:pb:group_partial_parition 
[[./figures/paxos.pdf]]



*** Avoid confusion by sequence numbers 

****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

- Server following a new leader should *promise* allegiance to the new
  one, ignore commands from an old one
- But old one might indeed be resurrected, and new one might fail:
  cannot make that switch for ever
- We need a notion of sequence or /round numbers/, indicating which
  leader is currently trusted
  - Commands from older rounds are ignored 

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


#+CAPTION: Server group with round numbers 
#+ATTR_LaTeX: :width 0.75\linewidth :options page=6
#+NAME: fig:consensus:pb:mutlicast
[[./figures/paxos.pdf]]


** Protocol 
*** From strawman to protocol 

- The strawman discussion should have reminded you of essential
  protocol mechanisms we need
  - Timeouts and retransmissions of messages
  - Heartbeating to help in failure detection 
  - Uneven number of servers, to decide on a majority in case of
    partitions
  - Leader election
  - Round numbers for elected leaders, to deal with switching leader
    role back and forth 
- We still skimmed  over a couple of details
  - E.g., how to behave when recovering after failure

#+BEAMER: \pause
Let's see how PAXOS works in more detail! 


*** Roles 
- *Client*: 
  - Makes requests to one or several proposers 
  - One request can lead to several proposals with different values!
  - Waits for response 
- *Proposer*:
  - Shepherds a client request 
  - *Proposes* a decision value, gives it a unique, monotonically
    increasing number  
  - Tries to convince acceptors to agree to request  
- *Leader*: 
  - A special role for one proposer 

*** Roles  (1) 

- *Acceptor* (voter): 
  - Keep the fault-tolerant, consistent state 
  - Grouped into Quorums
  - Can be part of multiple quorums for the same request 
- *Learner*: 
  - Carry out decisions taken by acceptors (e.g., send response to
    client) 
  - Multiple learners possible and typical 

*** Roles vs. processes 

- Typically, a physical process assumes multiple roles 
  - Usually, proposer, acceptor, and learner combined into one process 
- But an implementation matter
  - Compare \cite{Chandra:2007:PML:1281100.1281103} for implementation
    aspects 

*** Action: Propose, accept, choose 

- Values can be *proposed*
  - Based on client input, typically 
- Proposals can be *accepted*
- Proposals accepted by a quorum are *chosen* 
  - Cannot be undone!
  - Multiple proposals can only be chosen if they all have the same
    value 
- Chosen proposals can be sent back to clients
  - Made public


*** Paxos: Quorums 


- To make sure that enough information exists even in presence of
  failures, acceptors are grouped into quorums  
  - A quorum: A subset of acceptors 
  - A quorum must have more than half of all acceptors (a majority)
  - (Variations and generalizations exist) 
- Decisions are taken by a quorum of acceptors, not by all of them 


*** Paxos: Some intuition 

See \cite{paxos-made-simple}: 

- What happens if multiple proposals for a given request are made?
  (from different proposers)  
  - We require that at least one is accepted
  - Simple rule: An acceptor *accepts* the *first proposal* that it
    receives (P1) 
  - If more than one proposal is accepted, they all must decide for
    the same number (uniqueness)  

*** Paxos accepts multiple proposals? 


- Why not just accept one proposal and be done with it?

#+BEAMER: \pause

- Could stall:
  - Five acceptors, three proposals (red, green, blue) 
  - Red, blue proposal get to two servers each, first; green gets
    first to remaining server
  - No majority possible unless we allow change of mind! 

*** Paxos: Some intuition 

- Let’s give unique, ordered sequence numbers to proposals
  - Proposal is hence (value, sequence number) 
  - Uniqueness follows if, once a value $v$ for a a proposal with number
    $N$ has been chosen, all proposals with $N^\prime > N$ choose the
    same value $v$ (P2)  

*** Paxos: Some intuition 

- But P1 & P2 would fail if 
  - some acceptor A has not received a proposal when some value $v$ is
    chosen  
  - A receives a slow communication with a low $N$ and another value
    $v’$  
- We need a stronger promise: 
  - If a proposal with value $v$ is chosen, then every higher-numbered
    proposal issued by any proposer has value $v$  
  - How does a proposer ensure this? Needs to talk to acceptors, and
    extract a promise out of them not to accept any other proposals in
    the future!  



** Normal operation 
*** Paxos: Normal operation 

- Client sends request to proposer
- Proposer
  - assigns new number to request (say, $N$) 
  - runs the $N$ th instance of the algorithm by sending messages to a
    quorum 
  - (separate algorithm instance per request; can be optimised) 
- Operation in rounds, each with two phases 
  - Phase 1a: Prepare
  - Phase 1b: Promise 
  - Phase 2a: Accept Request 
  - Phase 2b: Accepted 



*** Paxos Phase 1: Prepare & Promise 

Phase 1a: Prepare 
  - Proposer creates proposed value $v$ with number $N$
    - Numbers must be unique, monotonically increasing per proposer 
  - Send ~Prepare(v,N)~ to chosen quorum 
    - Different quorums for each request possible (and typical) 

*** Paxos Phase 1: Prepare & Promise 

Phase 1b: Promise 
  - Acceptor compares received proposal number $N$ to the number of
    any other prepare requests to which it has already responded
  - $N$ larger than all others: Send back 
    - a ~Promise~ not to accept any more proposals less than $N$ 
    - the highest-numbered proposal (if any) that it already has
      accepted
    - Write $N$ to stable storage! 
  - $N$ smaller than some: Do nothing 
    - (Or send back a NACK, telling proposer that this proposal will
      not work) 


*** Paxos Phase 2: Accepting 

Phase 2a: Proposer sends ~Accept~ request
  - Once proposer has received promises from a quorum of
    acceptors: send out an ~Accept~ request with  
    - the value $v$ corresponding to highest-numbered request obtained 
      from the promises   
    - or with an arbitrary value, if no values were included in any
      promise  

*** Paxos Phase 2: Accepting 

Phase 2b: Acceptors receive Accept request 
  - Upon receiving an ~Accept~ request: accept value $v$ of the
    request
    - And write to stable storage 
    - Unless it has sent a promise to a prepare message with a higher
      value $N$
  - Send  ~Learn~ message to all learners, informing about $v$
    - To all or one, depending on fault assumptions
    - *Distinguished learner*, to inform all other learners 


Learning: 
  - Upon acceptance, an acceptor can inform all learners 
  - Learner actually accepts when it has received accept messages from
    a quorum (with the same value, of course)  



*** Paxos: Normal execution MSC 


#+CAPTION: Paxos regular run 
#+ATTR_LaTeX: :height 0.75\textheight :options page=7
#+NAME: fig:consensus:paxos:normal
[[./figures/paxos.pdf]]



** Operation with failures 

*** Paxos: Proposer  fails MSC 

#+CAPTION: Paxos proposer fails  
#+ATTR_LaTeX: :height 0.75\textheight :options page=8
#+NAME: fig:consensus:paxos:proposer_fails 
[[./figures/paxos.pdf]]


*** Paxos: Battling  Proposers 

#+CAPTION: Paxos proposer fails  
#+ATTR_LaTeX: :height 0.75\textheight :options page=9
#+NAME: fig:consensus:paxos:battling_proposer
[[./figures/paxos.pdf]]


*** Solving battling proposers 

- Break symmetry between multiple proposers, each trying to out-bid
  the other 
- A *dedicated proposer* gets preference
  - Basically, different timer values
  - Similar to dedicated learner 



*** Things to build with Paxos 

- Consensus in the strict sense
- Replicated state machine
  - Reliable (as far as possible), total order delivery of messages to
    components of the replicated state machine 
  - Building block: Log replication 



** Follow-up 

*** Paxos follow-up 

- Paxos paper triggered a lot of followup work (\href{http://paxos.systems/variants.html}{overview})
- Notable:
  - Vertical Paxos \cite{Lamport:2009:VPP:1582716.1582783}
    - Can deal with changing configuration while consensus in progress
  - Egalitarian Paxos \cite{Moraru:2013:MCE:2517349.2517350}
    - Relieve leader bottleneck

*** Paxos follow-up: RAFT 

RAFT \cite{Ongaro:2014:SUC:2643634.2643666} (and
\href{https://raft.github.io/raft.pdf}{extended version}) 

    - More restricted than Paxos, more specified in detail,
      practically oriented, 
      \href{https://raft.github.io}{plenty of implementations} 
      available   
    - Eg., proscribes that only most up-to-date server can become new
      leader
    - But does not address leader bottleneck issue
    - Material 
      - \href{http://thesecretlivesofdata.com/raft/}{Excellent 	animation} to explain RAFT
      - \href{https://raft.github.io}{Interactive animation}


* Log replication                                                  :noexport:


*** How to use Paxos to build Kafka 

- Recall Kafka and log aggregation in general
  - Multiple queues, all replicated
  - Multiple writers append to each queue
  - We want /total order/ for each queue (everybody sees same sequence
    of entries)
- Adding one entry to replicate queue is a single run of Paxos
  - I.e., agree on index where new value should sit in queue 



*** Efficient log aggregation 

- Running a separate Paxos per log addition is feasible, but
  inefficient 
- Do we really need promises for *every* new entry? Assuming proposer
  is relatively stable?
  - Not really: Pick a single proposer as *leader* 
  - Can aggregate effort; better with stable leader,  worse with
    frequently failing leader 
- *Multi-Paxos* (already in \cite{Lamport:1998:PP:279227.279229}) 
  - Compare \href{https://www.youtube.com/watch?v=JEpsBg0AO6o&feature=youtu.be}{Ousterhout lecture video }



*** Log aggregation setup 

- Each aggregator stores a replica of a queue
- A single proposer
- Multiple clients issue multiple append commands
- Goals:
  - No append is lost
  - All replicas store appends in same order 

*** Log aggregation protocol -- \href{https://ramcloud.stanford.edu/~ongaro/userstudy/paxos.pdf}{rough idea}  

- Client: send append command to leader, with unique IDs 
  - Clients can re-issue requests in case leader crashes 
- Leader proposes order
  - In normal operation, it just determines order -- proposals needed
    for fault tolerance
- Keep track of which appends-IDs go into which position 


*** Data flow? 

- Does data flow from client via proposer to all acceptors?
  - No, bottleneck
- Client can directly talk to all acceptors and ensure data is
  stored there
  - Possibly only afterwards talk to leader to get a number


#+BEAMER: \pause

- We have almost invented \ac{GFS} now -- see later for more details 


*** Example log aggregation 

- Kafka uses Zookeeper, which uses RAFT, for replication
- 
   \href{http://mesos.apache.org/documentation/latest/replicated-log-internals/}{Apache Mesos'} replicated log component, based on Paxos
- Corfu, intended for FLASH drives and their idiosyncrasies 
  \cite{Balakrishnan:2013:CDS:2542150.2535930},
  \cite{Malkhi:2012:PCF:2146382.2146391} 


* Byzantine agreement
   :PROPERTIES:
   :CUSTOM_ID: sec:consensus:byzt_alg
   :END:


*** Byzantine agreement 
   :PROPERTIES:
   :CUSTOM_ID: s:consensus:byzt_alg
   :END:


- So far: benign failure model (fail stop) 
- What if failures are due to attacks, corruption, strange
  malfunction, ...?
- Consensus still possible?

#+BEAMER: \pause

- Plausible expectations?
  - Surely no consensus with arbitrary number of compromised nodes
  - No expectations towards compromised nodes plausible 

*** Formally 

- *Agreement*: No two *nonfaulty* processes decide on different values  
- *Validity*: If all *nonfaulty* processes start with the same value,
  then this value is the only valid one 
- *Termination*: All *nonfaulty* processes eventually decide

*** Remarks 

- Faulty nodes can behave as they like
  - Hence, validity restricted to nonfaulty nodes 
- Algorithm for Byzantine agreement not necessarily good for
  consensus with failing processes 

*** Triple modular redundancy 

- Possibly natural expectation: each faulty node has to outvoted by
  two correct nodes
  - Hence: for $f$ faulty nodes, $3f$ nodes in total suffices
  - So-called *\ac{TMR}*

#+BEAMER: \pause
- Actually: not true!
  - Following slides give an idea why not 

*** TMR example 



****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

- Let us consider a simple three-node scenario
- Every node talks to every other node 
- One node might be faulty 

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


#+CAPTION: TMR counterexample setup
#+ATTR_LaTeX: :width 0.95\linewidth :options page=1
#+NAME: fig:consensus:tmr:setup
[[./figures/byzantine.pdf]]




*** Normal run 

****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

Round 1: Everybody sends its own value to its neighbor


#+CAPTION: TMR counterexample: normal run, step 1
#+ATTR_LaTeX: :width 0.95\linewidth :options page=2
#+NAME: fig:consensus:tmr:normal1
[[./figures/byzantine.pdf]]


*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


 Round 2: Everybody sends value of each neighbor to the other neighbor

#+CAPTION: TMR counterexample: normal run, step 2
#+ATTR_LaTeX: :width 0.95\linewidth :options page=3
#+NAME: fig:consensus:tmr:normal2
[[./figures/byzantine.pdf]]



*** C is faulty  

****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

Round 1


#+CAPTION: TMR counterexample: C faulty , step 1
#+ATTR_LaTeX: :width 0.95\linewidth :options page=4
#+NAME: fig:consensus:tmr:Cfaulty1
[[./figures/byzantine.pdf]]


*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


Round 2

#+CAPTION: TMR counterexample: C faulty , step 2
#+ATTR_LaTeX: :width 0.95\linewidth :options page=5
#+NAME: fig:consensus:tmr:Cfaulty2
[[./figures/byzantine.pdf]]


*** Additional rounds? 

- Note: Additional rounds would not help
- Correct nodes cannot send more information
- Faulty nodes just could spread more confusion 

*** A is faulty  

****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

Round 1


#+CAPTION: TMR counterexample: A faulty , step 1
#+ATTR_LaTeX: :width 0.95\linewidth :options page=6
#+NAME: fig:consensus:tmr:Afaulty1
[[./figures/byzantine.pdf]]


*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


Round 2

#+CAPTION: TMR counterexample: A faulty , step 2
#+ATTR_LaTeX: :width 0.95\linewidth :options page=7
#+NAME: fig:consensus:tmr:Afaulty2
[[./figures/byzantine.pdf]]





*** B is faulty  

****                                                              :B_columns:
     :PROPERTIES:
     :BEAMER_env: columns
     :END:

*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

Round 1


#+CAPTION: TMR counterexample: B faulty , step 1
#+ATTR_LaTeX: :width 0.95\linewidth :options page=8
#+NAME: fig:consensus:tmr:Bfaulty1
[[./figures/byzantine.pdf]]


*****                                                                 :BMCOL:
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:


Round 2

#+CAPTION: TMR counterexample: B faulty , step 2
#+ATTR_LaTeX: :width 0.95\linewidth :options page=8
#+NAME: fig:consensus:tmr:Bfaulty2
[[./figures/byzantine.pdf]]






*** Taking stock: Decisions  

\small 
#+CAPTION: Taking stock of TMR -- decisions 
#+ATTR_LATEX: :align lllp{0.2\linewidth}
| Case     | Round 1                                                              | Round 2                                                              | Observation             |
|----------+----------------------------------------------------------------------+----------------------------------------------------------------------+-------------------------|
| Normal   | \includegraphics[valign=c,width=0.15\linewidth,page=2]{figures/byzantine.pdf}  | \includegraphics[valign=c,width=0.15\linewidth,page=3]{figures/byzantine.pdf} | All decide 0 or 1       |
| C faulty | \includegraphics[valign=c,width=0.15\linewidth,page=4]{figures/byzantine.pdf} | \includegraphics[valign=c,width=0.15\linewidth,page=5]{figures/byzantine.pdf} | A, B decide 1, validity |
| A faulty | \includegraphics[valign=c,width=0.15\linewidth,page=6]{figures/byzantine.pdf} | \includegraphics[valign=c,width=0.15\linewidth,page=7]{figures/byzantine.pdf} | B, C decide 0, validity |
| B faulty | \includegraphics[valign=c,width=0.15\linewidth,page=8]{figures/byzantine.pdf} | \includegraphics[valign=c,width=0.15\linewidth,page=9]{figures/byzantine.pdf} | A, C same (0 or 1)      |

*** Taking stock: Distinguishable 

Right columns show which cases are indistinguishable for each node 

\small 
#+CAPTION: Taking stock of TMR -- indistinguishable cases 
#+ATTR_LATEX: :align lllccc
| Case     | Round 1                                                              | Round 2                                                              | A | B | C |
|----------+----------------------------------------------------------------------+----------------------------------------------------------------------+---+---+---|
| Normal   | \includegraphics[valign=c, width=0.15\linewidth,page=2]{figures/byzantine.pdf} | \includegraphics[valign=c, width=0.15\linewidth,page=3]{figures/byzantine.pdf} |   |   |   |
| C faulty | \includegraphics[valign=c, width=0.15\linewidth,page=4]{figures/byzantine.pdf} | \includegraphics[valign=c, width=0.15\linewidth,page=5]{figures/byzantine.pdf} | x |   |   |
| A faulty | \includegraphics[valign=c, width=0.15\linewidth,page=6]{figures/byzantine.pdf} | \includegraphics[valign=c, width=0.15\linewidth,page=7]{figures/byzantine.pdf} |   |   | x |
| B faulty | \includegraphics[valign=c, width=0.15\linewidth,page=8]{figures/byzantine.pdf} | \includegraphics[valign=c, width=0.15\linewidth,page=9]{figures/byzantine.pdf} | x |   | x |





*** n=3, f=1 does not solve Byzantine Agreement

- Process A  
  - Decides 1 in case "C faulty"  (because of validity)
  - Cannot distinguish case "C faulty" and "B faulty"
  - Hence decides 1 in case "B faulty"
- Process C
  - Decides 0 in case "A faulty" (because of validity)
  - Cannot distinguish case "A faulty" and "B faulty"
  - Hence decides 0 in case "B faulty"
- But: Agreement forces A, C to decide the same in case "B faulty"

*** n=3, f=1 does not solve Byzantine Agreement

- So: A decides 1 if and only if decides 0 
- *Contradiction* 
  - Not a formal proof, but the core idea
  - We made no assumptions about communication structure, algorithm,
    etc. 

*** Synchronous Byzantine agreement algorithm 

- As one example: Byzantine agreement in a *synchronous* setting \cite{Berman1989}
  - With $n> 4f$ nodes, in $2(f+1)$ rounds, constant message size
- Idea: Do rounds of two phases
  - In each round, one node becomes /king/ for that round
  - Collects and redistributes data
  - Enough information exchanged to overrule traitors 


*** Algorithm pseudocode 

#+BEGIN_SRC python
def vote(id, initial_vote, num_proc, f):
    preference = [None] * num_proc
    preference[id] = initial_vote

    for k in range(f+1):
        # odd phase:
        broadcast (preference[id])
        preference[j] = receive_from(j) for j <> id
        majority_pref = most often value in perference
        multiplicity = number of occurences of majority_preference

	# even phase - next slide
#+END_SRC


*** Algorithm pseudocode 
        
#+BEGIN_SRC python
    for k in range(f+1): 
        # odd phase: see previous slie
        # even phase: 
        if id == k:
            broadcast majority_preference
        king_majority = receive from process k
            # possibly from yourself

        if mulitplicity > num_proc/2 + f:
            preference[id] = majority_pref
        else:
            preference[id] = king_majority

    decide for preference[id]
#+END_SRC

*** Example: n=5, f=1, 2(1+1) rounds (odd and even), 2nd node is traitor

\small

|          | Node          |     1 | 2       |     3 |     4 |     5 |
|          | Vote          |     7 | #       |     3 |     3 |     2 |
| Round    | Preferences   | 7---- | #       | --3-- | ---3- | ----2 |
|----------+---------------+-------+---------+-------+-------+-------|
| 1a       | Preferences   | 77332 | #       | 72332 |  7332 | 72332 |
|          | Majority      |     7 | #       |     2 |     3 |     2 |
|          | Multiplicity  |     2 | #       |     2 |     3 |     2 |
|----------+---------------+-------+---------+-------+-------+-------|
| 1b       | King majority |     7 |         |       |       |       |
|          | Preference    | 77332 |         | 72732 | 73372 | 72337 |
|----------+---------------+-------+---------+-------+-------+-------|
| 2a       | Preferences   | 72777 |         | 75777 | 73777 | 73777 |
|          | Majority      |     7 |         |     7 |     7 |     7 |
|          | Multiplicity  |     4 |         |     4 |     4 |     4 |
|----------+---------------+-------+---------+-------+-------+-------|
| 2b       | King majority |       | 1,2,3,4 |       |       |       |
|          | Preference    | 72777 |         | 75777 | 73777 | 73777 |
|----------+---------------+-------+---------+-------+-------+-------|
| Decision |               |     7 |         |     7 |     7 |     7 |

*** Powerful algorithms for Byzantine Agreement: EIG 

 - To achieve bound $n > 3f$ for Byzantine Agreement, better
   algorithms needed (which exist) 
 - Popular: Exponential Information Gathering 
 - Each node builds a tree of all the information all other nodes have
   achieved in all previous rounds  
 - Complex information exchange among nodes 
 - Relatively complex decisions rules
 - Overall, complicated problem with many variants (cp. e.g. \cite{7780366}) 



*** Practical Byzantine Agreement 

- View-change based approach to Byzantine Agreement
  \cite{Castro:2002:PBF:571637.571640}
- Assumes all messages are authenticated (source of a message is
  always clear, even for messages from traitor)
  - Simplifies problem 
- Also works for $n> 3f$, weak synchrony needed for liveness
  - I.e., with arbitrary message delays, algorithm can get stuck
  - But it is safe, will never make a wrong decision 

   

 
* Case studies

*** Systems so far 

- Zookeeper, Chubby: Use Paxos to ensure consistent states
- Filesystems (Ceph, XtreemFS) use Paxos-based approach 
- \href{https://github.com/etcd-io/etcd}{etcd} (distributed, reliable
  key/value-store) uses RAFT   
  - Raft: Plenty of implementations available (\href{https://raft.github.io}{List})

*** etcd 

From the \href{https://github.com/etcd-io/etcd}{marketing brochure}: 

#+BEGIN_QUOTE
etcd is a distributed reliable key-value store for the most critical data of a distributed system, with a focus on being:

- *Simple*: well-defined, user-facing API (gRPC)
- *Secure*: automatic TLS with optional client cert authentication
- *Fast*: benchmarked 10,000 writes/sec
- *Reliable*: properly distributed using Raft

etcd is written in Go and uses the Raft consensus algorithm to manage a highly-available replicated log.
#+END_QUOTE

- Usage: e.g., in Kubernetes 

*** etcd Architecture 

- Designed for small amounts of key/value data, able to fit in memory 
- With
\href{https://github.com/etcd-io/etcd/tree/master/etcdctl}{command-lineclient} (in particular, ~put~, ~get~, ~del~ operations) 



* Summary 
  
*** Summary 


- Achieving  consensus is perhaps *the* core problem of distributed
  systems
  - Essential building block for many design approaches, like state
    machine replication, atomic multicast, ... 
- Its impossibility in general settings in unavoidable
  - Intricacies: node failures, delayed messages, network partition 
- Even in restricted settings, it is a complicated algorithmic problem
  - Leading to algorithms like Paxos and RAFT
- The complexity of solving it is the reason for the existence of
  systems like Chubby, Zookeeper, and others 


